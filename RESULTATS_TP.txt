Synthèse des expérimentations
=============================
Corpus utilisé : LibriSpeech dev-clean (sous-échantillon de 500 fichiers, dont
400 pour l’entraînement et 100 pour la validation). Tous les modèles optimisent
la loss CTC et produisent des prédictions en greedy decoding.

Résumé chiffré
--------------
| Partie | Architecture principale             | Loss validation approx. |
|--------|-------------------------------------|--------------------------|
| 1      | MLP + MFCC                          | 2.79                     |
| 2      | CNN + MelSpectrogram                | 2.34                     |
| 3      | BiLSTM (bidirectionnel)             | 2.33                     |
| 4      | Transformer allégé                  | 5.83                     |
| 5      | Optuna (BiLSTM + MelSpectrogram)    | 2.97*                    |
(*) Partie 5 n’utilise que 300 échantillons pour accélérer les essais Optuna.

Analyse synthétique
-------------------
1. Partie 1 — MLP + MFCC : le modèle prédit presque exclusivement le symbole
   “blank”. La loss diminue mais les sorties restent vides, faute de mémoire
   temporelle.
2. Partie 2 — CNN + MelSpectrogram : première architecture capable de produire
   des séquences lisibles. Les convolutions exploitent mieux les spectrogrammes
   (80 bandes mel).
3. Partie 3 — RNN : LSTM, GRU et surtout BiLSTM améliorent nettement le score.
   Le BiLSTM est retenu comme référence (perte 2.33) grâce à sa capacité à
   intégrer le contexte passé et futur. Le modèle hybride CNN+LSTM n’apporte pas
   de gain supplémentaire sur ce corpus réduit.
4. Partie 4 — Transformer : même avec un modèle allégé (d_model=64), la
   convergence reste mauvaise sur 500 exemples. Le modèle dérive vers des
   sorties répétitives.
5. Partie 5 — Optuna : permet d’automatiser la recherche d’hyperparamètres.
   L’essai gagnant privilégie un BiLSTM bidirectionnel, MelSpectrogram (71
   canaux), 3 couches et un taux d’apprentissage de 7.7e-3. Les graphiques de
   suivi sont regroupés dans `partie5/`.

Fichiers à consulter
--------------------
- `partie1/part1_training_curves.png` : courbes de perte MLP
- `partie2/part2_training_curves.png` : courbes CNN
- `partie3/part3_architecture_comparison.png` : comparaison LSTM/GRU/BiLSTM
- `partie4/part4_transformer_comparison.png` : évolution de la loss Transformer
- `partie5/part5_tuning_summary.png` : résumé des 10 essais Optuna
- `partie5/part5_best_params.json` : hyperparamètres retenus

Conclusion
----------
Sur ce volume de données, les architectures récurrentes restent la meilleure
option : une BiLSTM bidirectionnelle, alimentée par des MelSpectrogram, offre la
meilleure précision tout en gardant un coût de calcul raisonnable. Les approches
Transformer deviendraient pertinentes avec un corpus beaucoup plus volumineux
(et potentiellement un apprentissage pré-entraîné de type wav2vec2/Whisper).
